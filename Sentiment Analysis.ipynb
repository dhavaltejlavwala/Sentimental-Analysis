{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# @InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
    "#   author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
    "#   title     = {Learning Word Vectors for Sentiment Analysis},\n",
    "#   booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
    "#   month     = {June},\n",
    "#   year      = {2011},\n",
    "#   address   = {Portland, Oregon, USA},\n",
    "#   publisher = {Association for Computational Linguistics},\n",
    "#   pages     = {142--150},\n",
    "#   url       = {http://www.aclweb.org/anthology/P11-1015}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries for machine learining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing libraries for machine learining\")\n",
    "# Import all libraries for machine learning\n",
    "%matplotlib inline\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time \n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class sentimental_analysis:\n",
    "    \n",
    "    def load_files(self, files):\n",
    "        return load_svmlight_files(files, n_features=None, dtype=None)\n",
    "\n",
    "    # Calculating Tf-Idf for training and testing\n",
    "    def tfidf(self, training_data, testing_data):\n",
    "        tf_transformer = TfidfTransformer()\n",
    "\n",
    "        print(\"Training_data TF-IDF\")\n",
    "        #  It computes the TF for each review, the IDF using each review, and finally the TF-IDF for each review\n",
    "        training_data_tfidf = tf_transformer.fit_transform(training_data)\n",
    "        print(training_data_tfidf.shape)\n",
    "\n",
    "        print(\"Testing_data TF-IDF\")\n",
    "        # .transform on the testing data which computes the TF for each review, \n",
    "        # then the TF-IDF for each review using the IDF from the training data \n",
    "        testing_data_tfidf = tf_transformer.transform(testing_data)\n",
    "        print(testing_data_tfidf.shape)\n",
    "\n",
    "        return [training_data_tfidf,testing_data_tfidf]\n",
    "\n",
    "    # Binerize target data\n",
    "\n",
    "    # Converting target into binary\n",
    "    def binerize (self, raw_target):    \n",
    "        binerize_target = []\n",
    "        for i in range(len(raw_target)):\n",
    "            if raw_target[i] > 5:\n",
    "                binerize_target.append(1) # Positive\n",
    "            else:\n",
    "                binerize_target.append(0) # Negative\n",
    "        return binerize_target\n",
    "\n",
    "    # Train and test Logistic Regression Classifier\n",
    "    def lrc(self, training_data, raw_training_target, testing_data, raw_testing_target):\n",
    "        print(\"Binerizing target ...\")\n",
    "        training_target = self.binerize(raw_training_target)\n",
    "        testing_target = self.binerize(raw_testing_target)\n",
    "        start = time()\n",
    "        logreg = LogisticRegression()\n",
    "        print(\"Training ...\")\n",
    "        logreg.fit(training_data, training_target)\n",
    "        print(\"Training Done\")\n",
    "        print(\"Testing ...\")\n",
    "        logreg_accuracy = logreg.score(testing_data, testing_target) * 100\n",
    "        end = time()\n",
    "        return [logreg, round(logreg_accuracy,2), str(round((end-start), 2))]\n",
    "    \n",
    "    # Train and test Linear SVM Classifier with and without parameter \n",
    "    def lSVC(self, training_data, raw_training_target, testing_data, raw_testing_target, parameter=False):\n",
    "        print(\"Binerizing target ...\")\n",
    "        training_target = self.binerize(raw_training_target)\n",
    "        testing_target = self.binerize(raw_testing_target)\n",
    "        start = time()\n",
    "        if parameter == True:        \n",
    "            result_lSVC= self.lSVC_para(training_data, training_target, testing_data, testing_target)\n",
    "            end = time()\n",
    "            return [result_lSVC[0], round(result_lSVC[1],2), result_lSVC[2], str(round((end-start), 2))]\n",
    "        else:\n",
    "            clf_linear = LinearSVC()\n",
    "            print(\"Training ...\")\n",
    "            clf_linear.fit(training_data, training_target)\n",
    "            print(\"Training Done\")\n",
    "            print(\"Testing ...\")\n",
    "            result_lSVC = clf_linear.score(testing_data, testing_target)*100    \n",
    "            end = time()\n",
    "            return [clf_linear, round(result_lSVC,2), str(round((end-start), 2))]\n",
    "    \n",
    "    # Calculating best parameter for LinearSVC Classifier\n",
    "    def lSVC_para(self, training_data, training_target, testing_data, testing_target):\n",
    "        print(\"Calculating best parameter for LinearSVC Classifier ...\")\n",
    "        clist = 2**np.array(range(-2, 10), dtype='float')\n",
    "        cvscores = []\n",
    "        for c in clist:\n",
    "            print(c)\n",
    "            clf= LinearSVC(C=c)\n",
    "            scores = cross_val_score(clf, training_data, training_target, cv=3)\n",
    "            print(\"score\", scores)\n",
    "            cvscores.append(scores.mean()*100)\n",
    "            bestscore, bestC = max([(val, clist[idx]) for (idx, val) in enumerate(cvscores)])\n",
    "        print('Best CV accuracy =', round(bestscore,2), '% achieved at C =', bestC)\n",
    "\n",
    "        # Retrain on whole trainning set using best C value obtained from Cross validation\n",
    "        print(\"Retrain on whole trainning set using best C value obtained from Cross validation\")\n",
    "        clf = LinearSVC(C=bestC)\n",
    "        clf.fit(training_data, training_target)\n",
    "        accu = clf.score(testing_data, testing_target)*100\n",
    "        return [clf, accu, bestC]\n",
    "\n",
    "    # Train and test Random Forest Classifier\n",
    "    def random_forest(self, training_data, raw_training_target, testing_data, raw_testing_target):\n",
    "        print(\"Binerizing target ...\")\n",
    "        training_target = self.binerize(raw_training_target)\n",
    "        testing_target = self.binerize(raw_testing_target)\n",
    "        start = time()\n",
    "        print(\"Training ...\")\n",
    "        clf_forest = RandomForestClassifier(n_estimators = 100, min_samples_leaf=5, max_features='auto', max_depth=16)\n",
    "        clf_forest.fit(training_data, training_target)\n",
    "        print(\"Training Done\")\n",
    "        print(\"Testing ...\")\n",
    "        clf_forest_accuracy = clf_forest.score(testing_data, testing_target)*100\n",
    "        end = time()\n",
    "        return [clf_forest, round(clf_forest_accuracy,2),str(round((end-start), 2))]\n",
    "\n",
    "    # Train and test Kernel SVM Classifier\n",
    "    def kernel_SVM(self, training_data, raw_training_target, testing_data, raw_testing_target):\n",
    "        print(\"Binerizing target ...\")\n",
    "        training_target = self.binerize(raw_training_target)\n",
    "        testing_target = self.binerize(raw_testing_target)\n",
    "        start = time()\n",
    "        clf_kernel = SVC()\n",
    "        print(\"Training ...\")\n",
    "        clf_kernel.fit(training_data, training_target)\n",
    "        print(\"Training Done\")\n",
    "        print(\"Testing ...\")\n",
    "        end = time()\n",
    "        clf_kernel_accuracy = clf_kernel.score(testing_data, testing_target)*100\n",
    "        end = time() \n",
    "        return [clf_kernel, round(clf_kernel_accuracy,2),str(round((end-start), 2))]\n",
    "    \n",
    "    # Prediction from Random Forest \n",
    "    def prediction(self, obj_clf,fileName,labels):\n",
    "        pre = obj_clf.predict(testing_data)\n",
    "        print(\"Done\")\n",
    "        prediction_result = []\n",
    "        for i in range(len(pre)):\n",
    "            if pre[i] == 0:\n",
    "                prediction_result.append(str(i) + \", negative\") \n",
    "            else:\n",
    "                prediction_result.append(str(i) + \", positive\") \n",
    "        self.save_csv(prediction_result, fileName, labels)\n",
    "        \n",
    "    # Storing prediction in CSV file\n",
    "    def save_csv(self, prediction_result, fileName, labels):\n",
    "        print(\"Creating CSV file\")\n",
    "        # Open File\n",
    "        output_file = open(fileName+\".csv\",'w')\n",
    "        output_file.write(','.join(labels)+\"\\n\")\n",
    "        # Write data to file\n",
    "        for r in prediction_result:\n",
    "            output_file.write(r + \"\\n\")\n",
    "        output_file.close()\n",
    "        print(\"File saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Feature Extraction\n",
    "# print(\"Feature Extraction\")\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(training_data.data)\n",
    "# X_train_counts.shape\n",
    "# print(X_train_counts)\n",
    "\n",
    "# # Term Frequency\n",
    "# print(\"Term Frequency\")\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "# X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "# X_train_tf.shape\n",
    "# print(X_train_tf)\n",
    "\n",
    "# # TF-IDF\n",
    "# print(\"TF-IDF\")\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape\n",
    "# print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Converting dataset into float for training and testing purpose.\n",
    "\n",
    "# training_data = training_data.astype(np.float)\n",
    "# raw_training_target = raw_training_target.astype(np.float)\n",
    "# testing_data = testing_data.astype(np.float)\n",
    "# raw_testing_target = raw_testing_target.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binerize both training and testing target\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "# lb = preprocessing.LabelBinarizer()\n",
    "# lb.fit(training_target)\n",
    "# lb.fit(testing_target)\n",
    "# # LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)\n",
    "# # lb.classes_array(training_target)\n",
    "# new_training_target = lb.transform(training_target)\n",
    "# new_testing_target = lb.transform(testing_target)\n",
    "# print(len(training_target))\n",
    "# print(len(testing_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Files ...\n",
      "Done\n",
      "Training_data TF-IDF\n",
      "(25000, 89527)\n",
      "Testing_data TF-IDF\n",
      "(25000, 89527)\n",
      "Logistic Regression Classifier\n",
      "Binerizing target ...\n",
      "Training ...\n",
      "Training Done\n",
      "Testing ...\n",
      "Accuracy =  88.32 % Time =  3.2 seconds\n",
      "Linear SVM Classifier \n",
      "Binerizing target ...\n",
      "Training ...\n",
      "Training Done\n",
      "Testing ...\n",
      "Accuracy =  87.9 % Time =  1.4 seconds\n",
      "Linear SVM Classifier With Parameter Selection\n",
      "Binerizing target ...\n",
      "Calculating best parameter for LinearSVC Classifier ...\n",
      "0.25\n",
      "score [ 0.85805136  0.86177106  0.87013922]\n",
      "0.5\n",
      "score [ 0.85325174  0.85913127  0.8643783 ]\n",
      "1.0\n",
      "score [ 0.84485241  0.85157187  0.85417667]\n",
      "2.0\n",
      "score [ 0.83717303  0.84233261  0.84349496]\n",
      "4.0\n",
      "score [ 0.82889369  0.83273338  0.83713394]\n",
      "8.0\n",
      "score [ 0.82277418  0.82793377  0.83269323]\n",
      "16.0\n",
      "score [ 0.81845452  0.82385409  0.82957273]\n",
      "32.0\n",
      "score [ 0.81725462  0.82277418  0.82861258]\n",
      "64.0\n",
      "score [ 0.81653468  0.82157427  0.82741239]\n",
      "128.0\n",
      "score [ 0.81593473  0.82097432  0.82621219]\n",
      "256.0\n",
      "score [ 0.81521478  0.82097432  0.82573212]\n",
      "512.0\n",
      "score [ 0.81557475  0.82085433  0.8256121 ]\n",
      "Best CV accuracy = 86.33 % achieved at C = 0.25\n",
      "Retrain on whole trainning set using best C value obtained from Cross validation\n",
      "Accuracy =  88.63 % at Best C =  0.25 Time =  267.79 seconds\n",
      "Random Forest Classifier\n",
      "Binerizing target ...\n",
      "Training ...\n",
      "Training Done\n",
      "Testing ...\n",
      "Accuracy =  82.16 % Time =  11.82 seconds\n",
      "Prediction for new dataset from classifier...\n",
      "Done\n",
      "Creating CSV file\n",
      "File saved!\n"
     ]
    }
   ],
   "source": [
    "# Store path in array for training and testing files\n",
    "files = [\"/data/aclImdb/train/labeledBow.feat\",\"/data/aclImdb/test/labeledBow.feat\"]\n",
    "\n",
    "# Object for sentiment_analysis\n",
    "sa = sentimental_analysis()\n",
    "\n",
    "# Load data for training_data, training_target and testing_data, testing_target \n",
    "print(\"Loading Files ...\")\n",
    "training_data, raw_training_target, testing_data, raw_testing_target = sa.load_files(files)\n",
    "print(\"Done\")\n",
    "\n",
    "# Count tf-idf for training and testing data\n",
    "tfidf_data = sa.tfidf(training_data, testing_data)\n",
    "\n",
    "training_data = tfidf_data[0]\n",
    "testing_data = tfidf_data[1]\n",
    "\n",
    "print(\"Logistic Regression Classifier\")\n",
    "result = sa.lrc(training_data, raw_training_target, testing_data, raw_testing_target)\n",
    "obj_lrc = result[0]\n",
    "print(\"Accuracy = \", result[1], \"% Time = \", result[2],\"seconds\")\n",
    "\n",
    "print(\"Linear SVM Classifier \")\n",
    "result = sa.lSVC(training_data, raw_training_target, testing_data, raw_testing_target)\n",
    "obj_lSCV = result[0]\n",
    "print(\"Accuracy = \", result[1], \"% Time = \", result[2],\"seconds\")\n",
    "\n",
    "print(\"Linear SVM Classifier With Parameter Selection\")\n",
    "result = sa.lSVC(training_data, raw_training_target, testing_data, raw_testing_target, True)\n",
    "obj_lSVC_para = result[0]\n",
    "print(\"Accuracy = \", result[1], \"% at Best C = \", result[2],\"Time = \", result[3],\"seconds\")\n",
    "\n",
    "print(\"Random Forest Classifier\")\n",
    "result = sa.random_forest(training_data, raw_training_target, testing_data, raw_testing_target)\n",
    "obj_random_forest = result[0]\n",
    "print(\"Accuracy = \", result[1], \"% Time = \", result[2],\"seconds\")\n",
    "\n",
    "# print(\"Kernel SVM Classifier\")\n",
    "# result = sa.random_forest(training_data, raw_training_target, testing_data, raw_testing_target)\n",
    "# obj_kernel_SVM = result[0]\n",
    "# print(\"Accuracy = \", result[1], \"% Time = \", result[2],\"seconds\")\n",
    "\n",
    "print(\"Prediction for new dataset from classifier...\")\n",
    "# You can pass any classifier's object for prediction data and file name\n",
    "labels = [\"review\",\"rating\"]\n",
    "sa.prediction(obj_random_forest, \"random\", labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
